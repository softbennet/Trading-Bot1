{
    "type": "Reinforcement Learning",
    "definition": {
        "text": "Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.",
        "updated": 1613197154946,
        "translations": [
            {
                "language": "RU",
                "text": "Обучение с подкреплением (RL) - это область машинного обучения, занимающаяся тем, как интеллектуальные агенты должны предпринимать действия в окружающей среде, чтобы максимизировать понятие совокупного вознаграждения. Обучение с подкреплением является одной из трех основных парадигм машинного обучения, наряду с контролируемым и неконтролируемым обучением.",
                "updated": 1645249613791
            },
            {
                "language": "TR",
                "text": "Takviyeli öğrenme (RL), kümülatif ödül kavramını en üst düzeye çıkarmak için akıllı ajanların bir ortamda nasıl eylemde bulunmaları gerektiği ile ilgilenen bir makine öğrenimi alanıdır. Takviyeli öğrenme, denetimli öğrenme ve denetimsiz öğrenmenin yanı sıra üç temel makine öğrenimi paradigmasından biridir.",
                "updated": 1654397467690
            },
            {
                "language": "DE",
                "text": "Verstärkungslernen (Reinforcement Learning, RL) ist ein Bereich des maschinellen Lernens, der sich mit der Frage beschäftigt, wie intelligente Agenten in einer Umgebung agieren sollten, um den Begriff der kumulativen Belohnung zu maximieren. Das Verstärkungslernen ist eines der drei grundlegenden Paradigmen des maschinellen Lernens, neben dem überwachten Lernen und dem unüberwachten Lernen.",
                "updated": 1705265628971
            }
        ]
    },
    "paragraphs": [
        {
            "style": "Text",
            "text": "Reinforcement learning differs from supervised learning in not needing labelled input/output pairs be presented, and in not needing sub-optimal actions to be explicitly corrected. Instead the focus is on finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge).",
            "updated": 1613197179841,
            "translations": [
                {
                    "language": "RU",
                    "text": "Обучение с подкреплением отличается от контролируемого обучения тем, что не требует представления пар \"вход/выход\" с метками и не требует явного исправления неоптимальных действий. Вместо этого основное внимание уделяется поиску баланса между исследованием (неизведанной территории) и эксплуатацией (текущих знаний).",
                    "updated": 1645249628011
                },
                {
                    "language": "TR",
                    "text": "Pekiştirmeli öğrenme, etiketli girdi/çıktı çiftlerinin sunulmasına ihtiyaç duymaması ve alt-optimal eylemlerin açıkça düzeltilmesine ihtiyaç duymaması bakımından denetimli öğrenmeden farklıdır. Bunun yerine odak noktası, keşif (keşfedilmemiş bölge) ve sömürü (mevcut bilgi) arasında bir denge bulmaktır.",
                    "updated": 1654397473767,
                    "style": "Text"
                },
                {
                    "language": "DE",
                    "text": "Das Verstärkungslernen unterscheidet sich vom überwachten Lernen dadurch, dass keine markierten Eingabe-/Ausgabepaare präsentiert werden müssen und dass suboptimale Aktionen nicht explizit korrigiert werden müssen. Stattdessen liegt der Schwerpunkt auf der Suche nach einem Gleichgewicht zwischen der Erkundung (von Neuland) und der Ausnutzung (des vorhandenen Wissens).",
                    "updated": 1705265638385
                }
            ]
        },
        {
            "style": "Text",
            "text": "The environment is typically stated in the form of a Markov decision process (MDP), because many reinforcement learning algorithms for this context use dynamic programming techniques. The main difference between the classical dynamic programming methods and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the MDP and they target large MDPs where exact methods become infeasible.",
            "updated": 1613197190452,
            "translations": [
                {
                    "language": "RU",
                    "text": "Среда обычно задается в виде марковского процесса принятия решений (MDP), потому что многие алгоритмы обучения с подкреплением для этого контекста и��пользуют методы динамического программирования. Основное различие между классическими методами динамического программирования и алгоритмами обучения с подкреплением заключается в том, что последние не предполагают знания точной математической модели MDP и нацелены на большие MDP, где точные методы становятся невыполнимыми.",
                    "updated": 1645249638743
                },
                {
                    "language": "TR",
                    "text": "Ortam tipik olarak bir Markov karar süreci (MDP) biçiminde ifade edilir, çünkü bu bağlam için birçok takviye öğrenme algoritması dinamik programlama tekniklerini kullanır. Klasik dinamik programlama yöntemleri ile takviyeli öğrenme algoritmaları arasındaki temel fark, ikincisinin MDP'nin kesin bir matematiksel modeli hakkında bilgi sahibi olduğunu varsaymaması ve kesin yöntemlerin uygulanamaz hale geldiği büyük MDP'leri hedeflemesidir.",
                    "updated": 1654397480819,
                    "style": "Text"
                },
                {
                    "language": "DE",
                    "text": "Die Umgebung wird in der Regel in Form eines Markov-Entscheidungsprozesses (MDP) angegeben, da viele Algorithmen für das Verstärkungslernen in diesem Zusammenhang Techniken der dynamischen Programmierung verwenden. Der Hauptunterschied zwischen den klassischen Methoden der dynamischen Programmierung und den Algorithmen des Verstärkungslernens besteht darin, dass letztere keine Kenntnis eines exakten mathematischen Modells des MDP voraussetzen und auf große MDPs abzielen, bei denen exakte Methoden nicht mehr durchführbar sind.",
                    "updated": 1705265651635
                }
            ]
        }
    ]
}